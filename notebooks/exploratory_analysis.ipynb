# %% [markdown]
# # üìä An√°lisis Exploratorio: Loter√≠a Melate
# 
# **Objetivo**: Analizar 30 sorteos reales para detectar (o descartar) patrones predictivos
# 
# **Hip√≥tesis nula**: Los sorteos son completamente aleatorios ‚Üí distribuci√≥n uniforme
# 
# **Autor**: [Tu nombre]  
# **Fecha**: 2024-11-08  
# **Dataset**: 30 sorteos Melate (M√©xico)

# %% [markdown]
# ## 1. Setup y Carga de Datos

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from scipy import stats
import json
import os
import warnings

warnings.filterwarnings('ignore')

# Configurar estilo
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 11

print("‚úÖ Librer√≠as cargadas")

# %%
# Cargar datos desde JSON
data_dir = './data/raw/'
files = sorted([f for f in os.listdir(data_dir) if f.endswith('.json')])

draws = []
for filename in files:
    with open(os.path.join(data_dir, filename), 'r', encoding='utf-8') as f:
        draw = json.load(f)
        draws.append(draw)

print(f"üìä Sorteos cargados: {len(draws)}")

# Convertir a DataFrame
df = pd.DataFrame([
    {
        'date': draw['date'],
        'numbers': draw['numbers'],
        'additional': draw['additional'],
        'sum': draw['sum'],
        'even_count': draw['even_count'],
        'odd_count': draw['odd_count'],
        'range': draw['range'],
        'hash': draw['hash'][:16]  # Solo primeros 16 chars
    }
    for draw in draws
])

df['date'] = pd.to_datetime(df['date'])
df = df.sort_values('date').reset_index(drop=True)

print("\nüìã Primeros 5 sorteos:")
df.head()

# %% [markdown]
# ## 2. Estad√≠sticas Descriptivas B√°sicas

# %%
print("=" * 80)
print("üìà ESTAD√çSTICAS DESCRIPTIVAS")
print("=" * 80)

# Todas las numbers aplanadas
all_numbers = []
for numbers in df['numbers']:
    all_numbers.extend(numbers)

print(f"\nüìä Total de n√∫meros extra√≠dos: {len(all_numbers)}")
print(f"   (30 sorteos √ó 6 n√∫meros = 180 esperados)")

# Frecuencias
freq = Counter(all_numbers)
print(f"\nüî¢ N√∫meros √∫nicos observados: {len(freq)}/56")

# Top 10 m√°s frecuentes
print("\nüèÜ Top 10 N√∫meros M√°s Frecuentes:")
for num, count in freq.most_common(10):
    expected = len(all_numbers) / 56  # Esperado si es uniforme
    print(f"   #{num:2d}: {count:2d} veces (esperado: {expected:.1f})")

# Bottom 10 menos frecuentes
print("\nüìâ Top 10 N√∫meros Menos Frecuentes:")
for num, count in freq.most_common()[-10:]:
    expected = len(all_numbers) / 56
    print(f"   #{num:2d}: {count:2d} veces (esperado: {expected:.1f})")

# Estad√≠sticas de suma
print("\n‚ûï Estad√≠sticas de Suma:")
print(f"   Promedio: {df['sum'].mean():.1f}")
print(f"   Mediana:  {df['sum'].median():.1f}")
print(f"   Std Dev:  {df['sum'].std():.1f}")
print(f"   Rango:    [{df['sum'].min()}, {df['sum'].max()}]")
print(f"   Te√≥rico:  ~171 ¬± 30")

# %% [markdown]
# ## 3. TEST ESTAD√çSTICO: Chi-Cuadrado (Uniformidad)

# %%
print("=" * 80)
print("üß™ TEST CHI-CUADRADO: ¬øDistribuci√≥n Uniforme?")
print("=" * 80)

# Frecuencias observadas
observed = np.array([freq.get(i, 0) for i in range(1, 57)])

# Frecuencias esperadas (uniforme)
expected = np.full(56, len(all_numbers) / 56)

# Chi-cuadrado test
chi2_stat, p_value = stats.chisquare(observed, expected)

print(f"\nüìä Resultados:")
print(f"   œá¬≤ estad√≠stico: {chi2_stat:.2f}")
print(f"   p-value:        {p_value:.4f}")
print(f"   Grados libertad: 55")
print(f"   Œ± cr√≠tico:      0.05")

if p_value > 0.05:
    print(f"\n‚úÖ CONCLUSI√ìN: No se rechaza H‚ÇÄ (p={p_value:.4f} > 0.05)")
    print("   ‚Üí La distribuci√≥n es consistente con uniformidad")
    print("   ‚Üí NO hay evidencia de n√∫meros 'calientes' o 'fr√≠os'")
else:
    print(f"\n‚ö†Ô∏è  CONCLUSI√ìN: Se rechaza H‚ÇÄ (p={p_value:.4f} < 0.05)")
    print("   ‚Üí La distribuci√≥n difiere significativamente de uniforme")
    print("   ‚Üí Requiere m√°s an√°lisis (tama√±o muestral peque√±o?)")

# %% [markdown]
# ## 4. VISUALIZACI√ìN 1: Frecuencia de N√∫meros

# %%
fig, axes = plt.subplots(2, 1, figsize=(16, 10))

# 4.1 Histograma de frecuencias
ax1 = axes[0]
numbers_sorted = sorted(freq.items())
x = [n for n, c in numbers_sorted]
y = [c for n, c in numbers_sorted]

bars = ax1.bar(x, y, color='steelblue', alpha=0.7, edgecolor='black')
ax1.axhline(y=len(all_numbers)/56, color='red', linestyle='--', linewidth=2, 
            label=f'Esperado (uniforme): {len(all_numbers)/56:.1f}')

# Colorear barras extremas
for i, (num, count) in enumerate(numbers_sorted):
    if count >= np.percentile(y, 90):
        bars[i].set_color('darkgreen')
    elif count <= np.percentile(y, 10):
        bars[i].set_color('darkred')

ax1.set_xlabel('N√∫mero (1-56)', fontsize=12)
ax1.set_ylabel('Frecuencia (# apariciones)', fontsize=12)
ax1.set_title('Distribuci√≥n de Frecuencias: 30 Sorteos Melate', fontsize=14, fontweight='bold')
ax1.legend(fontsize=11)
ax1.grid(axis='y', alpha=0.3)

# 4.2 Heatmap de frecuencias (matriz 7√ó8)
ax2 = axes[1]
freq_matrix = np.zeros((7, 8))
for num in range(1, 57):
    row = (num - 1) // 8
    col = (num - 1) % 8
    freq_matrix[row, col] = freq.get(num, 0)

im = ax2.imshow(freq_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=max(freq.values()))

# Anotaciones
for i in range(7):
    for j in range(8):
        num = i * 8 + j + 1
        if num <= 56:
            text = ax2.text(j, i, f'{num}\n({int(freq_matrix[i, j])})',
                           ha="center", va="center", color="black", fontsize=9)

ax2.set_xticks([])
ax2.set_yticks([])
ax2.set_title('Heatmap de Frecuencias (n√∫mero: apariciones)', fontsize=14, fontweight='bold')
cbar = plt.colorbar(im, ax=ax2)
cbar.set_label('Frecuencia', rotation=270, labelpad=20)

plt.tight_layout()
plt.savefig('./results/figures/frequency_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico guardado: ./results/figures/frequency_analysis.png")
plt.show()

# %% [markdown]
# ## 5. VISUALIZACI√ìN 2: Distribuci√≥n de Sumas

# %%
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# 5.1 Histograma de sumas
ax1 = axes[0]
ax1.hist(df['sum'], bins=15, color='steelblue', alpha=0.7, edgecolor='black')
ax1.axvline(df['sum'].mean(), color='red', linestyle='--', linewidth=2, 
            label=f'Media observada: {df["sum"].mean():.1f}')
ax1.axvline(171, color='orange', linestyle=':', linewidth=2, 
            label='Te√≥rico: 171')
ax1.set_xlabel('Suma de 6 n√∫meros', fontsize=12)
ax1.set_ylabel('Frecuencia', fontsize=12)
ax1.set_title('Distribuci√≥n de Sumas', fontsize=14, fontweight='bold')
ax1.legend()
ax1.grid(axis='y', alpha=0.3)

# 5.2 Serie temporal
ax2 = axes[1]
ax2.plot(df['date'], df['sum'], marker='o', linestyle='-', color='steelblue', 
         markersize=6, alpha=0.7)
ax2.axhline(171, color='orange', linestyle=':', linewidth=2, label='Te√≥rico: 171')
ax2.axhline(df['sum'].mean(), color='red', linestyle='--', linewidth=2, 
            label=f'Media: {df["sum"].mean():.1f}')
ax2.fill_between(df['date'], 171-30, 171+30, alpha=0.2, color='orange', 
                  label='¬±1 std te√≥rico')
ax2.set_xlabel('Fecha', fontsize=12)
ax2.set_ylabel('Suma', fontsize=12)
ax2.set_title('Serie Temporal de Sumas', fontsize=14, fontweight='bold')
ax2.legend()
ax2.grid(alpha=0.3)
plt.xticks(rotation=45)

plt.tight_layout()
plt.savefig('./results/figures/sum_distribution.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico guardado: ./results/figures/sum_distribution.png")
plt.show()

# %% [markdown]
# ## 6. AN√ÅLISIS DE PARIDAD (Pares vs Impares)

# %%
print("=" * 80)
print("‚öñÔ∏è  AN√ÅLISIS DE PARIDAD")
print("=" * 80)

# Distribuci√≥n de pares/impares
parity_dist = df.groupby('even_count').size()

print("\nüìä Distribuci√≥n de N√∫meros Pares por Sorteo:")
for even_count, freq in parity_dist.items():
    print(f"   {even_count} pares / {6-even_count} impares: {freq} sorteos ({freq/len(df)*100:.1f}%)")

# Te√≥rico binomial (p=0.5)
from scipy.stats import binom
n = 6  # n√∫meros por sorteo
p = 0.5  # probabilidad de par

print("\nüìà Distribuci√≥n Te√≥rica (Binomial n=6, p=0.5):")
for k in range(7):
    theoretical_prob = binom.pmf(k, n, p)
    print(f"   {k} pares: {theoretical_prob*100:.1f}% (esperado: {theoretical_prob*30:.1f} sorteos)")

# Chi-cuadrado test
observed_parity = [parity_dist.get(k, 0) for k in range(7)]
expected_parity = [binom.pmf(k, n, p) * len(df) for k in range(7)]
chi2_parity, p_parity = stats.chisquare(observed_parity, expected_parity)

print(f"\nüß™ Test Chi-Cuadrado Paridad:")
print(f"   œá¬≤ = {chi2_parity:.2f}, p = {p_parity:.4f}")
if p_parity > 0.05:
    print("   ‚úÖ Distribuci√≥n de paridad consistente con azar")
else:
    print("   ‚ö†Ô∏è Desviaci√≥n significativa de paridad esperada")

# Visualizaci√≥n
fig, ax = plt.subplots(figsize=(10, 6))
x = range(7)
width = 0.35
ax.bar([i - width/2 for i in x], observed_parity, width, label='Observado', 
       color='steelblue', alpha=0.7)
ax.bar([i + width/2 for i in x], expected_parity, width, label='Esperado (Binomial)', 
       color='orange', alpha=0.7)
ax.set_xlabel('Cantidad de N√∫meros Pares', fontsize=12)
ax.set_ylabel('Frecuencia (# sorteos)', fontsize=12)
ax.set_title('Distribuci√≥n de Paridad: Observado vs Te√≥rico', fontsize=14, fontweight='bold')
ax.set_xticks(x)
ax.set_xticklabels([f'{k} pares' for k in x])
ax.legend()
ax.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('./results/figures/parity_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Gr√°fico guardado: ./results/figures/parity_analysis.png")
plt.show()

# %% [markdown]
# ## 7. AN√ÅLISIS DE AUTOCORRELACI√ìN (¬øHay memoria?)

# %%
print("=" * 80)
print("üîó AN√ÅLISIS DE AUTOCORRELACI√ìN")
print("=" * 80)

# Crear serie binaria: ¬øn√∫mero X aparece en sorteo t?
autocorr_results = {}

for num in [24, 30, 31, 44]:  # N√∫meros m√°s frecuentes
    series = [1 if num in draw['numbers'] else 0 for draw in draws]
    
    # Autocorrelaci√≥n lag-1
    acf_1 = pd.Series(series).autocorr(lag=1)
    autocorr_results[num] = acf_1
    
    print(f"\n#{num:2d}: ACF(lag=1) = {acf_1:.3f}")
    if abs(acf_1) < 0.2:
        print(f"     ‚úÖ No hay autocorrelaci√≥n significativa")
    else:
        print(f"     ‚ö†Ô∏è Posible autocorrelaci√≥n (requiere m√°s datos)")

# Test global: ¬øhay persistencia de sumas?
acf_sum = df['sum'].autocorr(lag=1)
print(f"\nüìä Autocorrelaci√≥n de Sumas (lag=1): {acf_sum:.3f}")
if abs(acf_sum) < 0.2:
    print("   ‚úÖ NO hay memoria entre sorteos consecutivos")
else:
    print("   ‚ö†Ô∏è Posible dependencia temporal")

# %% [markdown]
# ## 8. DETECCI√ìN DE PATRONES: Pares Frecuentes

# %%
print("=" * 80)
print("üë• AN√ÅLISIS DE PARES FRECUENTES")
print("=" * 80)

# Contar pares de n√∫meros que aparecen juntos
from itertools import combinations

pair_counts = Counter()
for draw in draws:
    for pair in combinations(sorted(draw['numbers']), 2):
        pair_counts[pair] += 1

# Top 10 pares
print("\nüèÜ Top 10 Pares M√°s Frecuentes:")
for pair, count in pair_counts.most_common(10):
    expected = len(draws) * (6 * 5 / 2) / (56 * 55 / 2)  # Prob. te√≥rica
    print(f"   {pair}: {count} veces (esperado: {expected:.2f})")

# ¬øAlg√∫n par significativamente frecuente?
max_count = pair_counts.most_common(1)[0][1]
expected_max = len(draws) * (6 * 5 / 2) / (56 * 55 / 2)

print(f"\nüìä Par m√°s frecuente: {max_count} apariciones")
print(f"   Esperado por azar: {expected_max:.2f}")
print(f"   Ratio: {max_count / expected_max:.2f}x")

if max_count / expected_max < 2.0:
    print("   ‚úÖ Dentro de variabilidad normal")
else:
    print("   ‚ö†Ô∏è Significativamente alto (requiere correcci√≥n Bonferroni)")

# %% [markdown]
# ## 9. RESUMEN EJECUTIVO

# %%
print("=" * 80)
print("üìã RESUMEN EJECUTIVO: AN√ÅLISIS EXPLORATORIO")
print("=" * 80)

print(f"""
üìä DATOS
‚Ä¢ Sorteos analizados: {len(draws)}
‚Ä¢ Per√≠odo: {df['date'].min().strftime('%Y-%m-%d')} a {df['date'].max().strftime('%Y-%m-%d')}
‚Ä¢ Total n√∫meros extra√≠dos: {len(all_numbers)}

üî¢ UNIFORMIDAD
‚Ä¢ Test Chi¬≤: œá¬≤={chi2_stat:.2f}, p={p_value:.4f}
‚Ä¢ Conclusi√≥n: {'‚úÖ Consistente con uniforme' if p_value > 0.05 else '‚ö†Ô∏è Desviaci√≥n significativa'}

‚ûï SUMA DE N√öMEROS
‚Ä¢ Promedio observado: {df['sum'].mean():.1f}
‚Ä¢ Esperado te√≥rico: 171 ¬± 30
‚Ä¢ Desviaci√≥n: {abs(df['sum'].mean() - 171):.1f} ({abs(df['sum'].mean() - 171)/30:.2f} std)

‚öñÔ∏è  PARIDAD
‚Ä¢ Test Chi¬≤ paridad: p={p_parity:.4f}
‚Ä¢ Conclusi√≥n: {'‚úÖ Distribuci√≥n normal' if p_parity > 0.05 else '‚ö†Ô∏è Desviaci√≥n detectada'}

üîó AUTOCORRELACI√ìN
‚Ä¢ Sumas (lag-1): {acf_sum:.3f}
‚Ä¢ Conclusi√≥n: {'‚úÖ NO hay memoria entre sorteos' if abs(acf_sum) < 0.2 else '‚ö†Ô∏è Posible dependencia'}

üë• PATRONES
‚Ä¢ Par m√°s frecuente: {pair_counts.most_common(1)[0][1]} apariciones
‚Ä¢ Ratio vs esperado: {max_count / expected_max:.2f}x
‚Ä¢ Conclusi√≥n: {'‚úÖ Dentro de variabilidad' if max_count / expected_max < 2.0 else '‚ö†Ô∏è Requiere an√°lisis'}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üéØ CONCLUSI√ìN GENERAL:

Los sorteos de Loter√≠a Melate muestran caracter√≠sticas consistentes con un 
proceso COMPLETAMENTE ALEATORIO. No se detectan patrones predictivos 
significativos en:
  ‚Ä¢ Distribuci√≥n de frecuencias
  ‚Ä¢ Suma de n√∫meros
  ‚Ä¢ Paridad (pares/impares)
  ‚Ä¢ Autocorrelaci√≥n temporal
  ‚Ä¢ Co-ocurrencia de pares

‚û°Ô∏è IMPLICACI√ìN: Es altamente improbable que algoritmos de Machine Learning
   puedan predecir sorteos futuros mejor que el azar puro (0.64 aciertos).
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
""")

# %%
print("\n‚úÖ AN√ÅLISIS COMPLETADO")
print("üìÅ Figuras guardadas en: ./results/figures/")
print("   - frequency_analysis.png")
print("   - sum_distribution.png")
print("   - parity_analysis.png")